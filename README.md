# Healthcare ETL

A Python-based ETL pipeline for processing FHIR JSON files and loading them into a MySQL database. Includes validation scripts and basic data exploration utilities.

## Table of Contents
- [Overview](#overview)
- [Requirements](#requirements)
- [Installation](#installation)
- [Usage](#usage)
- [Validation](#validation)
- [MySQL Setup](#mysql-setup)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)
- [License](#license)

## Overview

This repository contains:

- `healthcare_etl.py`: Main ETL script that:
  - Reads .json files from a specified directory (e.g. `fhir/`)
  - Extracts relevant FHIR data (Patients, Observations, etc.) with custom Python classes/functions
  - Loads the data into a MySQL database (or optionally into CSVs if you modify the code)
- `validate_etl.py`: Validation script that compares original file counts against processed results, checks data completeness, and runs basic spot checks on the data
- `fhir_explorer.py` (optional): Simple script for exploring FHIR data, if present
- `requirements.txt`: Lists Python dependencies
- `etl_logs/`: Contains logs generated by the pipeline (optional)
- `fhir/`: Directory with source JSON files (not always included or may be stored via Git LFS)
- `processed_data/`: Directory with CSV outputs (if configured), or large .json resources

## Requirements

- Python 3.8+ (or a similar version)
- MySQL server (if you want to load data into a MySQL database)
- pip or conda for installing Python dependencies

## Installation

1. Clone this repository:
```bash
git clone https://github.com/HAFDAOUIH/Medical-DS.git
cd Medical-DS
```

2. Install dependencies:
```bash
# If using pip
pip install -r requirements.txt


## Usage

### 1. Run the ETL

By default, the ETL expects a directory of .json FHIR files (e.g. `fhir/`) and a MySQL URL:

```bash
python3 healthcare_etl.py --input_dir fhir \
  --mysql_url "mysql+pymysql://username:password@localhost:3306/fhir_data"
```

- `--input_dir fhir`: Path to the folder containing FHIR JSON files
- `--mysql_url`: The SQLAlchemy-style connection string for MySQL (username, password, host, port, db name)

Pipeline steps:
1. Parallel extraction of FHIR JSON (in child processes)
2. Aggregation of extracted data in the main process
3. Creation of the MySQL engine in the main process
4. Insertion of each resource type into MySQL tables (e.g. patient, encounter, condition, etc.)

If everything is successful, you'll see log lines like:

```sql
Inserted 983 patient records into MySQL table 'patient'
Inserted 38450 encounter records into MySQL table 'encounter'
...
ETL Pipeline completed:
 - Duration: XX.XX seconds
 - Total files processed: N
 - Total resources processed: M
```

### 2. Validate the Results

After the ETL finishes, you can run:

```bash
python3 validate_etl.py --input_dir fhir --output_dir processed_data
```

- `--input_dir fhir`: The same folder of JSON files
- `--output_dir processed_data`: Where your CSV or processed data might exist (if you used CSV output in your code), or to compare resource counts

This script:
- Counts the original FHIR records in each file
- Checks the CSV outputs (or processed files)
- Reports any mismatches in counts, data completeness, or potential issues

You'll see a summary report like:

```yaml
=== ETL Validation Report ===
Total processed records: 432,827
Total original records: 432,827
Overall difference: 0
...
RESOURCE:
  - Processed: 7,304
  - Original: 7,304
  - Data completeness: 93%
```

## MySQL Setup

1. Start MySQL server (on Ubuntu):
```bash
sudo systemctl start mysql
```

2. Log into the MySQL shell:
```bash
mysql -u root -p
```

3. Create a database if you don't already have one:
```sql
CREATE DATABASE fhir_data;
```

4. Grant privileges to your user if needed

5. Verify with:
```sql
SHOW DATABASES;
USE fhir_data;
SHOW TABLES;
```

When you run the ETL, it will automatically create tables named after each FHIR resource (e.g., patient, encounter, observation) and insert the data.

## Test the API : 

### API Description

This API provides endpoints to upload files for ETL (Extract, Transform, Load) processing and retrieve Electronic Medical Records (EMR) data for a specific patient.

#### Endpoints:

1. **POST /upload**:
   - This endpoint allows the user to upload files or a folder for ETL processing.
   - **Parameters**:
     - `files`: A list of files (JSON, XML, CSV) to be uploaded.
     - `folder`: (Optional) A folder containing files to be uploaded.
     - `mysql_url`: The MySQL connection URL for storing the processed data (required).
   - **Process**:
     - The API processes the uploaded files or the files within the provided folder, applies the ETL pipeline, and stores the results in the specified MySQL database (`healthcare_db`).
     - Valid file types include JSON, XML, and CSV.
   - **Response**:
     - Returns a success message if the files are processed successfully.
     - Returns an error message if no valid files are found, if the folder path is invalid, or if there is any issue during the ETL process.

2. **GET /emr/<patient_id>**:
   - This endpoint retrieves a patient's EMR data from the MySQL database.
   - **Parameters**:
     - `patient_id`: The unique identifier for the patient whose EMR data is to be retrieved.
     - `mysql_url`: The MySQL connection URL to connect to the database (required).
   - **Process**:
     - The API fetches the patient's data from the `patient` table in the `healthcare_db` MySQL database based on the provided `patient_id`.
     - Returns the patient's information if found.
     - If the patient is not found, an error message is returned.
   - **Response**:
     - A JSON object containing the patient's EMR data if found.
     - An error message if the patient is not found or if there are issues with the database connection.

#### Run the API :

navigate to bbackend folder first, then run this cmd in the terminal :

```bash
python3 api.py
```

#### Example Usage:

Open other Terminal and test the API :

** Warning: ** you must specify a database to store the files

**Upload Files**:

1. Upload a folder for ETL processing:
   ```bash
   curl -X POST http://127.0.0.1:5000/upload -F "folder=test_folder" -F "mysql_url=mysql+pymysql://root@localhost:3306/healthcare_db"
   ```

2. Upload multiple files for ETL processing:
   ```bash
   curl -X POST http://127.0.0.1:5000/upload -F "files=@Ross213_Bayer639_d084de98-b1f8-4b37-a91a-e6c5cc3e5d20.json" -F"files=@Sina65_Wolff180_582b89e2-30d8-44fb-bb96-03957b2ec7c2.json" -F "mysql_url=mysql+pymysql://root@localhost:3306/healthcare_db"
   ```

**Get Patient EMR**:

1. Retrieve a patient's EMR data:
   ```bash
   curl -X GET "http://127.0.0.1:5000/emr/eac150b8-3c32-4a24-b5da-e39d7dee588e?mysql_url=mysql+pymysql://root@localhost:3306/healthcare_db"
   ```

#### Configuration:

- **Upload Folder**: Files are stored temporarily in `./uploads` before processing.
- **Temporary Folder**: `./tmp` folder is used for storing files during ETL processing.
- **Allowed Extensions**: The API accepts `.json`, `.xml`, and `.csv` files for processing.

#### Error Handling:

- The API returns appropriate error messages for:
  - Missing `mysql_url`.
  - Unsupported file types.
  - Invalid folder paths.
  - Database connection issues.
  - No valid files found for processing.

This API helps automate the ETL process for healthcare data and facilitates the retrieval of medical records for specific patients stored in a MySQL database.

## Troubleshooting

- **No module named 'pymysql'**:
  - Make sure you've run `pip install -r requirements.txt` to install pymysql and other dependencies

- **ValueError: Could not parse date**:
  - The pipeline logs date parsing failures. Some FHIR JSON might have invalid date strings

- **MySQL insertion fails**:
  - Ensure your credentials and DB name are correct
  - Check MySQL is running and that you have permission to create/insert tables

- **Large Files**:
  - If your fhir data is very large and you have trouble uploading to GitHub, consider using Git LFS or storing data externally

- **Can't run script (Permission denied)**:
  - Use `python3 <filename>` or `chmod +x healthcare_etl.py` then `./healthcare_etl.py ...`

## Contributing

1. Fork this repo and create a feature branch
2. Make changes and add tests or documentation
3. Submit a pull request for review

## License

MIT License or whichever you prefer. (Include your chosen license text.)
