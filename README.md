# Medical Data Sapace Project 

## Healthcare ETL

A Python-based ETL pipeline for processing FHIR JSON files and loading them into a MySQL database. Includes validation scripts and basic data exploration utilities.

### Overview

This repository contains:

- `healthcare_etl.py`: Main ETL script that:
  - Reads .json files from a specified directory (e.g. `fhir/`)
  - Extracts relevant FHIR data (Patients, Observations, etc.) with custom Python classes/functions
  - Loads the data into a MySQL database (or optionally into CSVs if you modify the code)
- `validate_etl.py`: Validation script that compares original file counts against processed results, checks data completeness, and runs basic spot checks on the data
- `fhir_explorer.py` (optional): Simple script for exploring FHIR data, if present
- `requirements.txt`: Lists Python dependencies
- `etl_logs/`: Contains logs generated by the pipeline (optional)
- `fhir/`: Directory with source JSON files (not always included or may be stored via Git LFS)
- `processed_data/`: Directory with CSV outputs (if configured), or large .json resources

### Requirements

- Python 3.8+ (or a similar version)
- MySQL server (if you want to load data into a MySQL database)
- pip or conda for installing Python dependencies

### Installation

1. Clone this repository:
```bash
git clone https://github.com/HAFDAOUIH/Medical-DS.git
cd Medical-DS
```

2. Install dependencies:
```bash
# If using pip
pip install -r requirements.txt
```

### Usage

#### 1. Run the ETL

By default, the ETL expects a directory of .json FHIR files (e.g. `fhir/`) and a MySQL URL:

```bash
python3 healthcare_etl.py --input_dir fhir \
  --mysql_url "mysql+pymysql://username:password@localhost:3306/fhir_data"
```

- `--input_dir fhir`: Path to the folder containing FHIR JSON files
- `--mysql_url`: The SQLAlchemy-style connection string for MySQL (username, password, host, port, db name)

Pipeline steps:
1. Parallel extraction of FHIR JSON (in child processes)
2. Aggregation of extracted data in the main process
3. Creation of the MySQL engine in the main process
4. Insertion of each resource type into MySQL tables (e.g. patient, encounter, condition, etc.)

If everything is successful, you'll see log lines like:

```sql
Inserted 983 patient records into MySQL table 'patient'
Inserted 38450 encounter records into MySQL table 'encounter'
...
ETL Pipeline completed:
 - Duration: XX.XX seconds
 - Total files processed: N
 - Total resources processed: M
```

#### 2. Validate the Results

After the ETL finishes, you can run:

```bash
python3 validate_etl.py --input_dir fhir --output_dir processed_data
```

- `--input_dir fhir`: The same folder of JSON files
- `--output_dir processed_data`: Where your CSV or processed data might exist (if you used CSV output in your code), or to compare resource counts

This script:
- Counts the original FHIR records in each file
- Checks the CSV outputs (or processed files)
- Reports any mismatches in counts, data completeness, or potential issues

You'll see a summary report like:

```yaml
=== ETL Validation Report ===
Total processed records: 432,827
Total original records: 432,827
Overall difference: 0
...
RESOURCE:
  - Processed: 7,304
  - Original: 7,304
  - Data completeness: 93%
```

### MySQL Setup

1. Start MySQL server (on Ubuntu):
```bash
sudo systemctl start mysql
```

2. Log into the MySQL shell:
```bash
mysql -u root -p
```

3. Create a database if you don't already have one:
```sql
CREATE DATABASE fhir_data;
```

4. Grant privileges to your user if needed

5. Verify with:
```sql
SHOW DATABASES;
USE fhir_data;
SHOW TABLES;
```

When you run the ETL, it will automatically create tables named after each FHIR resource (e.g., patient, encounter, observation) and insert the data.

## API Docs

This API provides endpoints to upload files for ETL (Extract, Transform, Load) processing and retrieve Electronic Medical Records (EMR) data for a specific patient.

### Endpoints:

#### General

- **`/upload`**  
  Upload a folder or files.
  
- **`/patients`**  
  Retrieve all patients.

- **`/search_patient`**  
  Search for a patient by their `PATIENT_ID` or name.

#### Encounters

- **`/get_user_encounters`**  
  Get all encounters for a user by their `PATIENT_ID`.
  
- **`/get_encounter_details`**  
  Get encounter details by the encounter ID.

#### Observations

- **`/observations/patient`**  
  Retrieve all observations for a user by their `PATIENT_ID`.

#### Immunizations

- **`/immunizations/patient`**  
  Retrieve all immunizations for a user by their `PATIENT_ID`.

#### Medical Conditions

- **`/conditions/patient`**  
  Retrieve all conditions for a user by their `PATIENT_ID`.

#### Medication Requests

- **`/medication-requests/patient`**  
  Retrieve all medication requests for a user by their `PATIENT_ID`.

#### Care Plans

- **`/careplans/patient`**  
  Retrieve all care plans for a user by their `PATIENT_ID`.

---

### Testing the API

** Warning: ** you must specify a database to store the files

Open other Terminal and test the API :

#### Upload

```bash
curl -X POST http://127.0.0.1:5000/upload \
-F "folder=fhir_test" \
-F "mysql_url=mysql+pymysql://root@localhost:3306/healthcare_db"

curl -X POST http://127.0.0.1:5000/upload \
-F "files=@Ross213_Bayer639_d084de98-b1f8-4b37-a91a-e6c5cc3e5d20.json" \
-F "files=@Sina65_Wolff180_582b89e2-30d8-44fb-bb96-03957b2ec7c2.json" \
-F "mysql_url=mysql+pymysql://root@localhost:3306/healthcare_db"
```

#### Patients

```bash
curl -X GET "http://127.0.0.1:5000/patients?mysql_url=mysql+pymysql://root@localhost:3306/healthcare_db"
```

#### Search Patient

```bash
curl -X GET "http://127.0.0.1:5000/search_patient?mysql_url=mysql+pymysql://root@localhost:3306/healthcare_db&name=Connelly992"

curl -X GET "http://127.0.0.1:5000/search_patient?mysql_url=mysql+pymysql://root@localhost:3306/healthcare_db&PATIENT_ID=b171a869-6781-4902-963e-2c6f02b6a3a4"
```

#### User Encounters

```bash
curl -X GET "http://127.0.0.1:5000/get_user_encounters?mysql_url=mysql+pymysql://root@localhost:3306/healthcare_db&PATIENT_ID=b171a869-6781-4902-963e-2c6f02b6a3a4"
```

#### Encounter Details

```bash
curl -X GET "http://127.0.0.1:5000/get_encounter_details?mysql_url=mysql+pymysql://root@localhost:3306/healthcare_db&encounter_id=cf366dba-2ddb-4d68-9e02-f11e4a6f363e"
```

#### Observations

```bash
curl -X GET "http://127.0.0.1:5000/observations/patient?mysql_url=mysql+pymysql://root@localhost:3306/healthcare_db&PATIENT_ID=b171a869-6781-4902-963e-2c6f02b6a3a4"
```

#### Immunizations

```bash
curl -X GET "http://127.0.0.1:5000/immunizations/patient?mysql_url=mysql+pymysql://root@localhost:3306/healthcare_db&PATIENT_ID=b171a869-6781-4902-963e-2c6f02b6a3a4"
```

#### Medical Conditions

```bash
curl -X GET "http://127.0.0.1:5000/conditions/patient?mysql_url=mysql+pymysql://root@localhost:3306/healthcare_db&PATIENT_ID=b171a869-6781-4902-963e-2c6f02b6a3a4"
```

#### Medication Requests

```bash
curl -X GET "http://127.0.0.1:5000/medication-requests/patient?mysql_url=mysql+pymysql://root@localhost:3306/healthcare_db&PATIENT_ID=b171a869-6781-4902-963e-2c6f02b6a3a4"
```

#### Care Plans

```bash
curl -X GET "http://127.0.0.1:5000/careplans/patient?mysql_url=mysql+pymysql://root@localhost:3306/healthcare_db&PATIENT_ID=b171a869-6781-4902-963e-2c6f02b6a3a4"
```

### Run the API

navigate to bbackend folder first, then run this cmd in the terminal :

```bash
python3 api.py
```

#### Configuration:

- **Upload Folder**: Files are stored temporarily in `./uploads` before processing.
- **Temporary Folder**: `./tmp` folder is used for storing files during ETL processing.
- **Allowed Extensions**: The API accepts `.json`, `.xml`, and `.csv` files for processing.

#### Error Handling:

- The API returns appropriate error messages for:
  - Missing `mysql_url`.
  - Unsupported file types.
  - Invalid folder paths.
  - Database connection issues.
  - No valid files found for processing.

This API helps automate the ETL process for healthcare data and facilitates the retrieval of medical records for specific patients stored in a MySQL database.

### Troubleshooting

- **No module named 'pymysql'**:
  - Make sure you've run `pip install -r requirements.txt` to install pymysql and other dependencies

- **ValueError: Could not parse date**:
  - The pipeline logs date parsing failures. Some FHIR JSON might have invalid date strings

- **MySQL insertion fails**:
  - Ensure your credentials and DB name are correct
  - Check MySQL is running and that you have permission to create/insert tables

- **Large Files**:
  - If your fhir data is very large and you have trouble uploading to GitHub, consider using Git LFS or storing data externally

- **Can't run script (Permission denied)**:
  - Use `python3 <filename>` or `chmod +x healthcare_etl.py` then `./healthcare_etl.py ...`
